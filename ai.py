# -*- coding: utf-8 -*-
"""Untitled56.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qE_3RDUnDQw_TbSD5-8xeGwlx0j_hlqZ

# Initial
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
## read file
df = pd.read_csv('combine_esgscore_10y.csv')

## throw away unnecessary indicators
df_new = df.drop(columns = ['Environmental Pillar Score In the last 10 FY','ESG Score In the last 10 FY','Identifier','Company Name','ISIN Code','Company Name.1','Country of Exchange','GICS Industry Name','Social Pillar Score In the last 10 FY','Governance Pillar Score In the last 10 FY'])

## change the file into numeric to avoid NAN in the following steps
#df_new = df_new.apply(pd.to_numeric, errors='coerce')

##check output
print(df_new)

"""# Fill the spaces with the median and do group by based on date

Shihao Gu, Bryan Kelly, and Dacheng Xiu (Review of Financial Studies, Vol. 33, Issue 5, (2020),2223-2273) (see section 2.1 footnote 29)
"""

# Create filling function
def missing_to_median(column):
    median_value = column.median(skipna=True)
    return column.fillna(median_value)

### Interpolate annual median into NAN
dates = df_new['date']

gkx_filled = df_new.groupby('date').transform(missing_to_median)
print(gkx_filled.columns)

### merge original dates column into gkx_filled
gkx_filled['date'] = dates
print('Original data:')

df_new.head() # before filling

print('Interpolation data:')
print(gkx_filled)

### Copy gkx_filled_with_date to df_ranked for doing rank normalize
df_ranked = gkx_filled.copy()
df_ranked.head()

### 得到column names並刪除data column name
columns_to_rank = df_ranked.columns.difference(['date'])

"""# Rank normalize

A common processing method used in financial data to compare different data within the same time period.

Shihao Gu, Bryan Kelly, and Dacheng Xiu (Review of Financial Studies, Vol. 33, Issue 5, (2020),2223-2273) (see section 2.1 footnote 29)
"""

## create rank_norm function
def rank_norm(column):
    rank = column.rank(method='dense')
    return (rank-1)/(np.nanmax(rank)-1)

# Apply the function to df_ranked and store the new columns with '_rank' suffix:
df_ranked = df_ranked.groupby('date')[columns_to_rank].transform(rank_norm)
df_ranked = df_ranked.add_suffix('_rank')

df_ranked.head()

"""# Doing linear regression"""

import statsmodels.api as sm

from sklearn.model_selection import train_test_split

# Assuming 'Return On Assets - Actual\nIn the last 10 FY_rank' is your target variable (y)
target_column = 'Return On Assets - Actual In the last 10 FY_rank'

# Selecting features and target variable
X = df_ranked.drop(columns=[target_column])
y = df_ranked[target_column]

# Splitting the data into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Displaying the shapes of the resulting sets
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""# Model_1 without constant

Without constant ex: y= ax
"""

from sklearn.linear_model import LinearRegression
import pandas as pd

# Assume 'Return On Assets - Actual\nIn the last 10 FY_rank' is the target variable (y)
target_column = 'Return On Assets - Actual In the last 10 FY_rank'

# Select all columns except 'Return On Assets - Actual\nIn the last 10 FY_rank' as feature variables (X)
features_columns = [col for col in df_ranked.columns if col != target_column]

# Select the corresponding column for training
X = X_train
y = y_train

# 初始化線性回歸模型
model = LinearRegression()

# 构建回归模型
model = sm.OLS(y, X).fit()

#sse
sse = results.ssr
print(f'Sum of Squared Residuals (SSE): {sse}')

# 打印回归结果
model.summary()
#model.pvalues

"""# 計算測試集的結果 Calculate the results of the test set

Sum of Squared Residuals SSE
"""

# 模型預測值
y_pred = model.predict(X_test)

# 計算殘差
residuals = y_test - y_pred

# 計算殘差平方和 (SSE)
sse = (residuals**2).sum()

print(f'Sum of Squared Residuals (SSE): {sse}')

"""計算手動 R-squared"""

# 計算手動 R-squared
y_mean = np.mean(y_test)
y_pred = model.predict(X_test)
sst = np.sum((y_test - y_mean)**2)
ssr = np.sum((y_pred - y_mean)**2)
rsquared_manual = ssr / sst

print(f"手動計算的 R-squared: {rsquared_manual:.4f}")

"""Correlation"""

import numpy as np

# 提取係數
coefficients = [0.4534, -0.0280, -0.0190, 0.4393, 0.1269, -0.2427]  # 請替換成實際的係數

# 計算每個係數和因變數之間的相關性
correlations = []
for i, coef in enumerate(coefficients[0:]):  # 從第一個係數開始，因為無截距項
    correlation = np.corrcoef(X_test.iloc[:, i], y_test)[0, 1]
    correlations.append((X_test.columns[i], correlation))

# 顯示相關性
correlations_df = pd.DataFrame(correlations, columns=['Variable', 'Correlation'])
print(correlations_df)

"""# 畫出偏回歸線觀察各係數對模型的影響力 Draw a partial regression line to observe the influence of each coefficient on the model

Environmental Innovation Score In the last 10 FY_rank
"""

import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming your regression results are stored in a DataFrame called 'results'
# Make sure to replace 'results' with the actual variable storing your regression results
# You can extract the coefficients using results.params
coefficients = results.params[1:]

# Assuming your independent variables are in a DataFrame called 'X_test'
# Replace 'X_test' with the actual variable containing your independent variables
# You can extract the column names using X_test.columns
independent_variables = X_test.columns

# Assuming you have predictions y_pred
y_pred = model.predict(X_test)

# Extracting the correlation for 'Environmental Innovation Score'
correlation = np.corrcoef(X_test['Environmental Innovation Score In the last 10 FY_rank'], y_test)[0, 1]

# Plotting the partial regression plot for 'Environmental Innovation Score'
plt.figure(figsize=(8, 6))

# Plotting the actual values
sns.regplot(x=X_test['Environmental Innovation Score In the last 10 FY_rank'], y=y_test, scatter_kws={'alpha': 0.5}, label=f'Actual (Correlation: {correlation:.2f})')

# Plotting the predicted values
sns.scatterplot(x=X_test['Environmental Innovation Score In the last 10 FY_rank'], y=y_pred, color='red', label='Predicted', alpha=0.8)

# Adding labels and title
plt.xlabel('Environmental Innovation Score In the last 10 FY_rank')
plt.ylabel('Return On Assets - Actual In the last 10 FY_rank')
plt.title(f'Partial Regression Plot for Environmental Innovation Score\nCoefficient: -0.0190')

# Adding legend
plt.legend()

# Display the plot
plt.show()

"""Emissions Score In the last 10 FY_rank"""

import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming your regression results are stored in a DataFrame called 'results'
# Make sure to replace 'results' with the actual variable storing your regression results
# You can extract the coefficients using results.params
coefficients = results.params[1:]

# Assuming your independent variables are in a DataFrame called 'X_test'
# Replace 'X_test' with the actual variable containing your independent variables
# You can extract the column names using X_test.columns
independent_variables = X_test.columns

# Assuming you have predictions y_pred
y_pred = model.predict(X_test)

# Extracting the correlation for 'Environmental Innovation Score'
correlation = np.corrcoef(X_test['Emissions Score In the last 10 FY_rank'], y_test)[0, 1]

# Plotting the partial regression plot for 'Environmental Innovation Score'
plt.figure(figsize=(8, 6))

# Plotting the actual values
sns.regplot(x=X_test['Emissions Score In the last 10 FY_rank'], y=y_test, scatter_kws={'alpha': 0.5}, label=f'Actual (Correlation: {correlation:.2f})')

# Plotting the predicted values
sns.scatterplot(x=X_test['Emissions Score In the last 10 FY_rank'], y=y_pred, color='red', label='Predicted', alpha=0.8)

# Adding labels and title
plt.xlabel('Emissions Score In the last 10 FY_rank')
plt.ylabel('Return On Assets - Actual In the last 10 FY_rank')
plt.title(f'Partial Regression Plot for Emissions Score\nCoefficient: -0.0280')

# Adding legend
plt.legend()

# Display the plot
plt.show()

"""Resource Use Score"""

import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming your regression results are stored in a DataFrame called 'results'
# Make sure to replace 'results' with the actual variable storing your regression results
# You can extract the coefficients using results.params
coefficients = results.params[1:]

# Assuming your independent variables are in a DataFrame called 'X_test'
# Replace 'X_test' with the actual variable containing your independent variables
# You can extract the column names using X_test.columns
independent_variables = X_test.columns

# Assuming you have predictions y_pred
y_pred = model.predict(X_test)

# Extracting the correlation for 'Environmental Innovation Score'
correlation = np.corrcoef(X_test['Resource Use Score In the last 10 FY_rank'], y_test)[0, 1]

# Plotting the partial regression plot for 'Environmental Innovation Score'
plt.figure(figsize=(8, 6))

# Plotting the actual values
sns.regplot(x=X_test['Resource Use Score In the last 10 FY_rank'], y=y_test, scatter_kws={'alpha': 0.5}, label=f'Actual (Correlation: {correlation:.2f})')

# Plotting the predicted values
sns.scatterplot(x=X_test['Resource Use Score In the last 10 FY_rank'], y=y_pred, color='red', label='Predicted', alpha=0.8)

# Adding labels and title
plt.xlabel('Resource Use Score In the last 10 FY_rank')
plt.ylabel('Return On Assets - Actual In the last 10 FY_rank')
plt.title(f'Partial Regression Plot for Resource Use Score\nCoefficient: 0.1269')

# Adding legend
plt.legend()

# Display the plot
plt.show()

"""# Regression Line Visualization wtih no constant model"""

import numpy as np

# Extracting coefficients from the regression results
coefficient = 0.1269

# Generating x values for the regression line
x_values = X_test['Environmental Innovation Score In the last 10 FY_rank'].values

# Calculating corresponding y values using the regression equation
y_values = coefficient * x_values

# Calculating squared differences between predicted and actual values
squared_diff = (y_test - y_values)**2

# Calculating mean squared error
mse = np.mean(squared_diff)

# Calculating RMSE
rmse = np.sqrt(mse)

print(f'Root Mean Squared Error (RMSE): {rmse}')

import numpy as np

# Extracting coefficients from the regression results
coefficient = -0.0190

# Generating x values for the regression line
x_values = X_test['Environmental Innovation Score In the last 10 FY_rank'].values

# Calculating corresponding y values using the regression equation
y_values = coefficient * x_values

# Calculating squared differences between predicted and actual values
squared_diff = (y_test - y_values)**2

# Calculating mean squared error
mse = np.mean(squared_diff)

# Calculating RMSE
rmse = np.sqrt(mse)

print(f'Root Mean Squared Error (RMSE): {rmse}')

"""Model 2 with constant

With constant ex: y= ax+b,b=constant
"""

import statsmodels.api as sm

# Assume 'Return On Assets - Actual\nIn the last 10 FY_rank' is the target variable (y)
target_column = 'Return On Assets - Actual In the last 10 FY_rank'

# Select all columns except 'Return On Assets - Actual\nIn the last 10 FY_rank' as feature variables (X)
features_columns = [col for col in df_ranked.columns if col != target_column]

# Select the corresponding column for training
X = df_ranked[features_columns]
#X = X + 1e-10
y = df_ranked[target_column]
#y = y + 1e-10

# Add intercept (constant)
X = sm.add_constant(X)

# Initialize linear regression model
model_with_intercept_statsmodels = sm.OLS(y, X)

# Adaptation model
results = model_with_intercept_statsmodels.fit()

#sse
sse = results.ssr
print(f'Sum of Squared Residuals (SSE): {sse}')

# results
summary = results.summary()
summary

"""# 計算測試集的結果 Calculate the results of the test set"""

# 模型預測值
y_pred = model.predict(X_test)

# 計算殘差
residuals = y_test - y_pred

# 計算殘差平方和 (SSE)
sse = (residuals**2).sum()

print(f'Sum of Squared Residuals (SSE): {sse}')

# 計算手動 R-squared
y_mean = np.mean(y_test)
y_pred = model.predict(X_test)
sst = np.sum((y_test - y_mean)**2)
ssr = np.sum((y_pred - y_mean)**2)
rsquared_manual = ssr / sst

print(f"手動計算的 R-squared: {rsquared_manual:.4f}")

import numpy as np

# 提取係數
coefficients = [0.3590, 0.4443, 0.0015, -0.0108, 0.1562, 0.0518, -0.5312]  # 請替換成實際的係數

# 計算每個係數和因變數之間的相關性
correlations = []
for i, coef in enumerate(coefficients[1:]):  # 從第二個係數開始，因為第一個是截距項
    correlation = np.corrcoef(X_test.iloc[:, i], y_test)[0, 1]
    correlations.append((X_test.columns[i], correlation))

# 顯示相關性
correlations_df = pd.DataFrame(correlations, columns=['Variable', 'Correlation'])
print(correlations_df)

"""# 畫出偏回歸線觀察各係數對模型的影響力 Draw a partial regression line to observe the influence of each coefficient on the model.

Environmental Innovation Score In the last 10 FY_rank
"""

import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming your regression results are stored in a DataFrame called 'results'
# Make sure to replace 'results' with the actual variable storing your regression results
# You can extract the coefficients using results.params
coefficients = results.params[1:]

# Assuming your independent variables are in a DataFrame called 'X_test'
# Replace 'X_test' with the actual variable containing your independent variables
# You can extract the column names using X_test.columns
independent_variables = X_test.columns

# Assuming you have predictions y_pred
y_pred = model.predict(X_test)

# Extracting the correlation for 'Environmental Innovation Score'
correlation = np.corrcoef(X_test['Environmental Innovation Score In the last 10 FY_rank'], y_test)[0, 1]

# Plotting the partial regression plot for 'Environmental Innovation Score'
plt.figure(figsize=(8, 6))

# Plotting the actual values
sns.regplot(x=X_test['Environmental Innovation Score In the last 10 FY_rank'], y=y_test, scatter_kws={'alpha': 0.5}, label=f'Actual (Correlation: {correlation:.2f})')

# Plotting the predicted values
sns.scatterplot(x=X_test['Environmental Innovation Score In the last 10 FY_rank'], y=y_pred, color='red', label='Predicted', alpha=0.8)

# Adding labels and title
plt.xlabel('Environmental Innovation Score In the last 10 FY_rank')
plt.ylabel('Return On Assets - Actual In the last 10 FY_rank')
plt.title(f'Partial Regression Plot for Environmental Innovation Score\nCoefficient: -0.0108')

# Adding legend
plt.legend()

# Display the plot
plt.show()

"""Emissions Score In the last 10 FY_rank"""

import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming your regression results are stored in a DataFrame called 'results'
# Make sure to replace 'results' with the actual variable storing your regression results
# You can extract the coefficients using results.params
coefficients = results.params[1:]

# Assuming your independent variables are in a DataFrame called 'X_test'
# Replace 'X_test' with the actual variable containing your independent variables
# You can extract the column names using X_test.columns
independent_variables = X_test.columns

# Assuming you have predictions y_pred
y_pred = model.predict(X_test)

# Extracting the correlation for 'Environmental Innovation Score'
correlation = np.corrcoef(X_test['Emissions Score In the last 10 FY_rank'], y_test)[0, 1]

# Plotting the partial regression plot for 'Environmental Innovation Score'
plt.figure(figsize=(8, 6))

# Plotting the actual values
sns.regplot(x=X_test['Emissions Score In the last 10 FY_rank'], y=y_test, scatter_kws={'alpha': 0.5}, label=f'Actual (Correlation: {correlation:.2f})')

# Plotting the predicted values
sns.scatterplot(x=X_test['Emissions Score In the last 10 FY_rank'], y=y_pred, color='red', label='Predicted', alpha=0.8)

# Adding labels and title
plt.xlabel('Emissions Score In the last 10 FY_rank')
plt.ylabel('Return On Assets - Actual In the last 10 FY_rank')
plt.title(f'Partial Regression Plot for Emissions Score\nCoefficient: 0.0015')

# Adding legend
plt.legend()

# Display the plot
plt.show()

"""Resource Use Score In the last 10 FY_rank"""

import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming your regression results are stored in a DataFrame called 'results'
# Make sure to replace 'results' with the actual variable storing your regression results
# You can extract the coefficients using results.params
coefficients = results.params[1:]

# Assuming your independent variables are in a DataFrame called 'X_test'
# Replace 'X_test' with the actual variable containing your independent variables
# You can extract the column names using X_test.columns
independent_variables = X_test.columns

# Assuming you have predictions y_pred
y_pred = model.predict(X_test)

# Extracting the correlation for 'Environmental Innovation Score'
correlation = np.corrcoef(X_test['Resource Use Score In the last 10 FY_rank'], y_test)[0, 1]

# Plotting the partial regression plot for 'Environmental Innovation Score'
plt.figure(figsize=(8, 6))

# Plotting the actual values
sns.regplot(x=X_test['Resource Use Score In the last 10 FY_rank'], y=y_test, scatter_kws={'alpha': 0.5}, label=f'Actual (Correlation: {correlation:.2f})')

# Plotting the predicted values
sns.scatterplot(x=X_test['Resource Use Score In the last 10 FY_rank'], y=y_pred, color='red', label='Predicted', alpha=0.8)

# Adding labels and title
plt.xlabel('Resource Use Score In the last 10 FY_rank')
plt.ylabel('Return On Assets - Actual In the last 10 FY_rank')
plt.title(f'Partial Regression Plot for Resource Use Score\nCoefficient: 0.0518')

# Adding legend
plt.legend()

# Display the plot
plt.show()